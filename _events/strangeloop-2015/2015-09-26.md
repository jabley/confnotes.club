---
layout: post
title:  "Strange Loop 2015"
date:   2015-09-26 13:43:17
tags: oreilly strangeloop conference 2015
---

## I See What You Mean by Peter Alvaro

  I love query languages for many reasons, but mostly because of their semantics. Wait, come back! In contrast to most systems programming languages (whose semantics can be quite esoteric), the semantics of a query (given some inputs) are precisely its outcome -- rows in tables. Hence when we write a query, we directly engage with its semantics: we simply say what we mean. This makes it easy and natural to reason about whether our queries are correct: that is, whether they mean what we intended them to mean.

  Query languages have traditionally been applied to a relatively narrow domains: historically, data at rest in data stores; more recently, data in motion through continuous, "streaming" query frameworks. Why stop here? Could query languages do for a notoriously complex domain such as distributed systems programming what they have done so successfully for data management? How would they need to evolve to become expressive enough to capture the programs that we need to write, while retaining a simple enough semantics to allow mere mortals to reason about their correctness?

  I will attempt to answer these questions (and raise many others) by describing a query language for distributed programming called Dedalus. Like traditional query languages, Dedalus abstracts away many of the details we typically associate with programming, making data and time first-class citizens and relegating computation to a subordinate role, characterizing how data is allowed to change as it moves through space and time. As we will see, this shift allows programmers to directly reason about distributed correctness properties such as consistency and fault-tolerance, and lays the foundations for powerful program analysis and repair tools (such as Blazes and LDFI), as well as successive generations of data-centric programming languages (including Bloom, Edelweiss and Eve).

  A discussion about Time and Data in distributed systems. It looks at how query languages and constraints can help us, if we have an abstraction that embraces them. Really interesting talk about Dedalus and the work that he's been doing at Netflix.

## Managing Containers At Scale with CoreOS and Kubernetes by Kelsey Hightower

Mainly a live demo of using K8s to to manager a cluster, doing canaries and rolling live updates.

## Unconventional programming with Chemical Computing by Carin Meier

Chemical programming is all about reactions. Simple and elegant. You can model it to create resilient, self-healing systems. Composes well. Eliminates incidental sequentiality, which can lead to improved concurrency.

https://github.com/gigasquid/chemical-computing

## How to have your Causality and Wall Clocks, Too by Jon Moore

- Distributed Monotonic Clocks (DMC)
  - Reflect causality and can track human time too
  - Operational reset buttons needed (to correct clock drift)
  - Population protocol flocking to avoid resets
  - Accommodates (some) clockless modes
- More work needed
  - Formal proofs?

## Propositions as Types by Philip Wadler

A deep talk about logic and programming.

Maths is discovered, not invented. See Church, Godel and Turing equivalence.

### Curry-Howard correspondence
1. propositions as types
1. proofs as programs
1. normalisation (simplification) of proofs as evaluation of programs

Every good idea will be discovered twice. Once by a logician, once by a computer scientist.

Most of you use programming languages that are invented, not discovered. And you can tell!

So this is an invitation to use programming languages that are discovered.

## Safe and fast parsers with Nom and Rust by Geoffroy Couprie

A talk about a parser combinator library for Rust, which is being used in VLC for dealing with media files. Rust:
- is memory-safe
- is type-safe
- is immutable by default
- talks easily to C

Nom offers:
- byte-oriented or bit-oriented
- zero-copy (memory efficient)
- streaming (both push and pull)
- macro-based syntax
- descriptive errors

## When 'Worst' is Best (In Distributed Systems) by Peter Bailis

We don't tend to provision hardware to cope with everyone on the planet accessing our service
Nor to cope with sending our laptop to Mars
Or having an FIS attacking our service.

Designing for the worst case often penalises the average case.

When can designing for the worst case improve the average case?

### Distributed systems

Networks make design hard. Many things can go wrong

Packets may be delayed
Packets may be dropped

Availability addresses delays and drops: any replica can respond to any request
Coordination-free systems (which don't need to talk) can:

1. be infinitely scaled out
1. improve throughput
1. ensure low latency
1. guarantee always-on response

Systems that behave well during network faults can behave better in non-faulty environments too
With good designs, popular guarantees from today's RDBMSs can benefit; eg read committed implementation

Also useful for:

automatic failover, server upgrades etc

Improving tail latency of a microservice — your service's corner case may be its consumers average case (depending on fanout and architecture).

Universal design – designing to accommodate the wheelchair user may also benefit non-wheelchair users (pedestrians, cyclists).

From the W3C site on a11y:

"There is a strong business case for accessibility. Accessibility overlaps with other best practices such as mobile web design, device independence, multi-modal interaction, usability, design for older users, and search engine optimisation (SEO)."

"Case studies show that accessible websites have better search results, reduced maintenance costs, and increased audience reach, among other benefits."

##  Building Scalable Stateful Services by Caitie McCaffrey

See high scalability notes — http://highscalability.com/blog/2015/10/12/making-the-case-for-building-scalable-stateful-services-in-t.html

When stateful services can scale and perform better.
Where does state live in your service? Is it all in the database, are you encoding an FSM in that? Sometimes it can give better performance to move state out of the database and into a service. This can mean reproducing classic database literature in the application tier.

Static hashing, consistent hashing, distributed hash table (DHT)
How to avoid the thundering herd.

## Reloading state
- First connection can be expensive. Use busy indicator to create the perception of progress
- Recovering from crashes
- Deploying updates

Decouple memory lifetime from process lifetime

You should read database literature papers. You can cherry-pick the part that is applicable to your context.

## Apache Kafka and the next 700 Stream Processing Systems by Jay Kreps

3 paradigms for programming:

1. request / response
1. batch
1. stream processing

# Faster Objects and Arrays by Gil Tene

Very interesting talk about work to provide faster access to POJOs via a library, which JDKs can then optimise into C struct speeds. I tend to really like all of Gil's talks, and this is no exception.

#Visualising Programme Execution by Jan Paul Posma

Experience report of how he's looked at tooling for debugging. Seemed to explore some of the themes that has shown in his videos. Early days for it so far, but looks promising.

# HTTP/2 in Erlang by Joe DeVivo

Great fast tour of Erlang features for implementing binary protocols, and how HTTP/2 works. I'm pretty familiar with the HTTP/2 implementation for Go, so I found it interesting to compare the explicit finite-state machine approach of Erlang.

# Streams — the data structure we need by Pam Selle

Good shoutout to SICP with Streams are a delayed list, then a look at stream implementations for JavaScript, and how that ties up with Reactive programming.

# All In With Determinism for Performance and Testing in Distributed Systems by John Hugg

Using VoltDB as the patient, he talks about the trade-offs that they made and how they've created a good product. A little bit sales-pitchy, but VoltDB has some lovely ideas and looks really good (especially given AWS new 2TB RAM instances)

# Beating Threads — live coding with real-time by Sam Aaron

Lovely look at the abstractions and motivation behind Sonic Pi. I'm going to be pointing my kids at this!

# Literate interactive coding — Devcards by Bruce Hauman

How to speed up the feedback loop for frontend development, and maintain a state of flow.

Problem — UI coding is endless tweaking, highly iterative process which is expensive.
Code, reload, interact to get to same state, then verify.

Solution — hot code reloading (using figwheel) => just write code that is reloadable.

Writing reloadable code has other benefits than just allowing quicker feedback cycles.

Write UI code outside of your main application. You can do something like literate programming to show the components that are developed, create tests cases, etc. Seems like a really interesting approach (sadly CLJS only at the moment).

# When the OS gets in the Way by Mark Price

Talk from LMAX about handling jitter due to the OS or GC.

We have a producer, and one or more consumers. Make this quick!

Fix the other things, so that response times are less than 10ms. Then apply these techniques.

The computer will be running threads doing:
- application purpose (receiving work items and putting them on a queue, taking them off the queue and processing)
- application runtime house-keeping (JVM GC threads, JIT compilation)
- OS house-keeping

Use Zing (or rewrite your application to use object pooling everywhere).

Tune the BIOS. Most are set up with general purpose settings. This is a whole talk in itself.
Discover what's available. Use `lstopo` on Linux to understand this.

## First attempt
- Use `isolcpus` to reserve CPU resource (for OS house-keeping tasks)
  - kernel boot time parameter
  - isolcpus=0-5,10-13
  - the OS will run on !isolcpus, leaving the rest available for your application
- Use `taskset` to pin your application to CPUs
  - `taskset -c 10-13 java ...`
  - JVM house-keeping can run on these threads
- Set affinity of the hot threads (putting work on the queue, taking things off the queue)
  - `sched_setaffinity` (which is usable from the JVM via C-interoperability)

Problem with this – taskset doesn't understand scheduling, so everything runs in a single core. In this example, that leaves 3 cores unused.

## Second attempt

Use `cpusets` instead. This is based on Linux cgroups and lets you carve up hierarchies.

- Isolate the OS by creating a cpuset and moving everything to that
  - `cset set --set=/system --cpu=6-9`
    - create a cpuset with CPUs 6 to 9
    - create it at the path (namespace?) `/system`
  - `cset proc --move --from-set=/ --to-set=/system -k --threads --force`
    - move all processes from `/` to `/system`
    - `-k` move unbound kernel threads
    - `--threads` move child threads

Run the application:

- `cset set --set=/app --cpu=0-5,10-13`
- `cset proc --exec /app taskset -cp 10-13 java ...`
  - Start a process in the /app cpuset
  - Run the program on CPUs 10 to 13
- `sched_setaffinity()` to pin the hot threads to cpus 1, 3, 5

Confirm this works using Linux `perf` -- in particular, looking for scheduler events to ensure things are not being switched off the CPU.

They are being switched. Hmmm.

Switch to using `ftrace`.

Check why a kernel worker thread is being switched onto our core (that we thought was allocated for java work).

# Look Ma, no OS! - An introduction to unikernels and their applications by Matt Bajor
